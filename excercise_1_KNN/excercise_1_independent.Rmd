---
title: "exc1_person_indep"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(class)
library(caret)
library(swirl)
```

1.3.4 Person independent KNN: Now try to apply k-nearest neighbor classification to the complete
data set from all students attending the course.
Distinguish two cases: Having data from all individuals in the training set (case A)
and splitting the data according to individuals (case B). 
Generate and explain the results. 
```{r reading dataset}

set.seed(423)

load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
```

## case A:
# Having data from all individuals in the training set
``` {r case A}
#DONT KNOW WHY IT GIVES ERRORS!

load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)

# id - huge dataframe with everyone as TRAINING
train_df <- id
id_train_labels <- train_df[,1]

person_error_v <- c()
# individually test sets for each person
for (person_df in idList){
  print("new_person")
  test_df <- person_df
  id_test_labels <- person_df[,1]
  
  # get the prediction
  numbers_test_pred <- knn(train = train_df, test = test_df,cl = id_train_labels, k=15)
  
  person_error <- mean(id_test_labels != numbers_test_pred)
  person_error_v <- c(person_error_v, person_error)
} 

#print(paste0("dim(person_error_v) = ", dim(person_error_v)))
plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case A")

```
``` {r plot case A}
plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case A")
```

## case B:
# splitting the data according to individuals
``` {r case B}
set.seed(423)

load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)

person_error_v <- c()
for (person_df in idList){
  # use individually data for training and testing
  shuffled_df <- person_df[sample(nrow(person_df)),]
  
  test_df <- shuffled_df[1:200,]
  train_df <- shuffled_df[201: 400,]
  
  id_test_labels <- test_df[,1]
  id_train_labels <- train_df[,1]
  
  # get the prediction
  numbers_test_pred <- knn(train = train_df, test = test_df,
  cl = id_train_labels, k=30)
  
  person_error <- mean(id_test_labels != numbers_test_pred)
  person_error_v <- c(person_error_v, person_error)
  
}

plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case B")

```

## Performance of sample size
1.3.5. Lastly report computational time of the prediction step for varying ‘k’ and using a small and large datasets. You don’t have to test every ‘k’ simply give an overview. Discuss how the accuracy changes with different sizes of the dataset, is ‘k’ dependent on the dataset size?

``` {r sample size}
k_accuracy_avg_vec <- c()
k_error_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)

# for k in ks
#   for i in len(listDF): # change size of the dataset
#     dataset_train = people joined
#     dataset_test = 1 person
#     shuffle dataset
#     split 50/50 for training and test (ask!!!)
#     do knn and calculate error

# with that we have to keep track of the error with regard to:
# k, sample size, MSE, time

# 1st:
#   person A training, person B test    -> time
#   A,B train, C test                -> time
#   A,B,C train, D test                 -> time
#   ...
# Is it the diagrams?

how to get the proper k -> how it effects the operating time

1 - 

```
