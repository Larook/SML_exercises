id_test_labels <- test_df[,1]
id_train_labels <- train_df[,1]
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df,
cl = id_train_labels, k=30)
person_error <- mean(id_test_labels != numbers_test_pred)
person_error_v <- c(person_error_v, person_error)
}
plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case B")
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
test_df <- shuffled_df[1:20000,]  # shuffled_df[1:360,]
train_df <- shuffled_df[20001:40000,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(class)
library(caret)
library(swirl)
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
# Case A - smaller dataset
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
#test_df <- shuffled_df[1:20000,]  # shuffled_df[1:360,]
#train_df <- shuffled_df[20001:40000,] # shuffled_df[361:400,]
# try to decrease the sample size so it can be run
test_df <- shuffled_df[1:300,]  # shuffled_df[1:360,]
train_df <- shuffled_df[301:600,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
#plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="300 training 300 testing")
# Case B - bigger dataset
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
test_df <- shuffled_df[1:500,]  # shuffled_df[1:360,]
train_df <- shuffled_df[501:1000,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
#plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="500 training 500 testing")
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
# Case A - smaller dataset
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
#test_df <- shuffled_df[1:20000,]  # shuffled_df[1:360,]
#train_df <- shuffled_df[20001:40000,] # shuffled_df[361:400,]
# try to decrease the sample size so it can be run
test_df <- shuffled_df[1:300,]  # shuffled_df[1:360,]
train_df <- shuffled_df[301:600,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
#plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="300 training 300 testing")
# Case B - bigger dataset
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
test_df <- shuffled_df[1:500,]  # shuffled_df[1:360,]
train_df <- shuffled_df[501:1000,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
#plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="500 training 500 testing")
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
# Case A - smaller dataset
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
#test_df <- shuffled_df[1:20000,]  # shuffled_df[1:360,]
#train_df <- shuffled_df[20001:40000,] # shuffled_df[361:400,]
# try to decrease the sample size so it can be run
test_df <- shuffled_df[1:300,]  # shuffled_df[1:360,]
train_df <- shuffled_df[301:600,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error", main="300 training 300 testing")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="300 training 300 testing")
# Case B - bigger dataset
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
test_df <- shuffled_df[1:500,]  # shuffled_df[1:360,]
train_df <- shuffled_df[501:1000,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df, test = test_df, cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error", main="500 training 500 testing")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="500 training 500 testing")
str(test_df)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
load("data/id100.Rda")
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split 10/90 for training and testing data
test_df <- shuffled_df[1:200,]  # shuffled_df[1:360,]
train_df <- shuffled_df[201:400,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]")
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
load("data/id100.Rda")
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c( 19)
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split 10/90 for training and testing data
test_df <- shuffled_df[1:200,]  # shuffled_df[1:360,]
train_df <- shuffled_df[201:400,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]")
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
load("data/id100.Rda")
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split 10/90 for training and testing data
test_df <- shuffled_df[1:200,]  # shuffled_df[1:360,]
train_df <- shuffled_df[201:400,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]")
# CASE A
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING
train_df <- id
id_train_labels <- train_df[,1]
person_error_v <- c()
# individually test sets for each person
for (person_df in idList){
print("new_person")
test_df <- person_df
id_test_labels <- person_df[,1]
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=15)
person_error <- mean(id_test_labels != numbers_test_pred)
person_error_v <- c(person_error_v, person_error)
}
#print(paste0("dim(person_error_v) = ", dim(person_error_v)))
plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case A")
# CASE B
person_error_v <- c()
for (person_df in idList){
# use individually data for training and testing
shuffled_df <- person_df[sample(nrow(person_df)),]
test_df <- shuffled_df[1:200,]
train_df <- shuffled_df[201: 400,]
id_test_labels <- test_df[,1]
id_train_labels <- train_df[,1]
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=30)
person_error <- mean(id_test_labels != numbers_test_pred)
person_error_v <- c(person_error_v, person_error)
}
plot(1:length(idList), person_error_v, type="o", ylab="misclassification error", xlab="person number", main="case B")
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
set.seed(423)
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
ks <- c(1, 5, 9, 15, 19, 25, 29)
# ks <- 1:40
# Case A - smaller dataset
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
#test_df <- shuffled_df[1:20000,]  # shuffled_df[1:360,]
#train_df <- shuffled_df[20001:40000,] # shuffled_df[361:400,]
# try to decrease the sample size so it can be run
test_df <- shuffled_df[1:300,]  # shuffled_df[1:360,]
train_df <- shuffled_df[301:600,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error", main="300 training 300 testing")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="300 training 300 testing")
# Case B - bigger dataset
k_error_avg_vec <- c()
timing_now_avg_vec <- c()
for (k_now in ks ){
#print(paste0("k_now = ", k_now))
k_error <- 0
k_error_avg <- 0
timing_now_avg <- 0
for (i in 1:10) {
# shuffle dataset
shuffled_df <- id[sample(nrow(id)),]
# split for training and testing data
test_df <- shuffled_df[1:500,]  # shuffled_df[1:360,]
train_df <- shuffled_df[501:1000,] # shuffled_df[361:400,]
# get the labels - supervision part
id_train_labels <- train_df[,1]
id_test_labels <- test_df[,1]
# check the time
t_start <- Sys.time()
# get the prediction
numbers_test_pred <- knn(train = train_df[,c(2:325)], test = test_df[,c(2:325)], cl = id_train_labels, k=k_now)
timing_now <- (Sys.time() - t_start ) * 1000 #ms
k_error <- k_error +mean(id_test_labels != numbers_test_pred)
timing_now_avg <- timing_now_avg + timing_now
}
# get summary of one k
k_error_avg <- k_error / 10
k_error_avg_vec <- c(k_error_avg_vec, k_error_avg)
timing_now_avg <- timing_now_avg / 10
timing_now_avg_vec <- c(timing_now_avg_vec, timing_now_avg)
print(paste0("k_now = ", k_now, " k_error_avg = ", k_error_avg, " timing_now_avg=", timing_now_avg ))
}
plot(ks, k_error_avg_vec, type="o", ylab="misclassification error", main="500 training 500 testing")
plot(ks, timing_now_avg_vec, type="o", ylab="average execution time [ms]", main="500 training 500 testing")
