---
title: "Exercise_3_clustering"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(class)
library(caret)
library(swirl)

#loading libraries and dataset
library(data.table) # working with ranges 
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization

# load('../data/id100.Rda') # dataset
```

```{r plot functions}
# get accuracy of the labels in percents
get_accuracy <- function(predicted_labels, test_labels){
  # accuracy(table(numbers_test_pred,id_test_labels))
  tab <- table(predicted_labels, test_labels)
  sum(diag(tab)/(sum(rowSums(tab)))) * 100
}

library(ggplot2)
knn_get_kmeans_plot_cv_data <- function(test_data, test_labels, train_data, train_labels, fold_no, k, title_info){
  # dont print training data validation when doing cross validation
      
    test_time_v <- c()
    test_accuracy_v <- c()
    train_accuracy_v <- c()
    
    for (rep in c(1:10)){
      t_start <- as.numeric(proc.time())
      # get the prediction
      numbers_test_pred <- knn(train = train_data, test = test_data, cl = train_labels, k=k)
      t_end <- as.numeric(proc.time())
      delta_t <- (t_end -  t_start)[3]  # seconds
      test_time_v <- c(test_time_v, delta_t)
      #print(test_time_v)
      
      # see the performance on testing data
      k_accuracy_test <-get_accuracy(test_labels, numbers_test_pred)
      test_accuracy_v <- c(test_accuracy_v, k_accuracy_test)

    }
    
    return(list("title_info"=title_info, "k"=k, "fold_no"=fold_no,"test_time_v"=test_time_v, "test_accuracy_v"=test_accuracy_v))
}

# change plot data to cv plotting appropriate data
get_cv_plot_data_kmeans <- function(plot_data_ks_l){
  # TODO: finish saving the data for cross validation
  df_goal <- data.frame()
  df_tmp <- data.frame(Reduce(rbind, plot_data_ks_l))
  # take all with k=3 and sum
  for (k in ks){
    df_k <- df_tmp[df_tmp$k==k,]
    # sum the test_time_v and test_accuracy_v
    time_v_sum <- rep(0, 10) # 10 repetitions
    acc_v_sum <- rep(0, 10)
    for (i in 1:nrow(df_k3)){
      time_v_sum <- time_v_sum + unlist(df_k$test_time_v[i])
      acc_v_sum <- acc_v_sum + unlist(df_k$test_accuracy_v[i])
    }
    time_v_avg <- time_v_sum / nrow(df_k)
    acc_v_avg <- acc_v_sum / nrow(df_k)
    df_row_k <- data.frame(df_k$title_info[1], k, mean(time_v_avg), sd(time_v_avg), mean(acc_v_avg), sd(acc_v_avg))
    names(df_row_k) <- c('title_info', 'k', 'mean_time', 'sd_time', 'mean_acc', 'sd_acc')
    df_goal <-rbind(df_goal, df_row_k)
  }
  return(df_goal)
}

# Plot all the results given the data
plot_results_cv_kmeans <- function(plot_data_ks_l){
  
  # translate average data to the cv
  df_cv_plot <- get_cv_plot_data_kmeans(plot_data_ks_l)
  
  main <- paste("Cross validation with 10 folds. Number of initial clusters = ", df_cv_plot$title_info)
  
  g_time <- ggplot(df_cv_plot, aes(x=ks)) + 
    geom_line(aes(y=mean_time)) + 
    geom_ribbon(aes(ymax=mean_time+sd_time, ymin=mean_time-sd_time), fill="pink", alpha=.5) +
    labs(title=main, 
         subtitle="execution time knn", 
         caption="Source: abcd", 
         y="time [ms]",
         x="k-number of nearest neighbours") 
  
  g_accuracy <- ggplot(df_cv_plot, aes(x=ks)) + 
    geom_line(aes(y=mean_acc, color="darkgreen")) + 
    geom_ribbon(aes(ymax=mean_acc+sd_acc, ymin=mean_acc-sd_acc), fill="green", alpha=.5) +
  labs(title=main, 
         subtitle="accuracy of knn", 
         caption="Source: abcd", 
         y="accuracy [%]",
         x="k-number of nearest neighbours")
  
  list_of_plots <- list(g_time, g_accuracy)
  
  return(list_of_plots)
}
```

# Exercise 3.1 K-means clustering:

## Try to improve the performance of two persons training data ( disjunct ). 
Perform K- means clustering of each cipher individually for the training set, in order to represent the training data as a number of cluster centroids. Now perform the training of the k-NN using the centroids of these clusters. You can try with different cluster sizes and see the resulting performance.
``` {r load data}

load("../data/idList-cornered-100-2021.Rdata") 
id <- do.call(rbind, idList[1:2])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)


# load whole data
# get 1 person as training, 2nd as testing
train_data_limit <- floor(nrow(id)/2)

test_rows_id <- 1:(train_data_limit)
train_rows_id <- (train_data_limit + 1) : nrow(id)

training_data <- id[train_rows_id, ]
testing_data <- id[test_rows_id, ]
```

``` {r reduce the dimensions of data using k-means}
set.seed(2345)


get_k_means_clustered_data <- function(dataset, k_init_clusters){
  cipher_cluster <- c()
  label_cluster <- c()

  for( digit in 0:9) {
  # digit <- 0
    digit_data <- dataset[ dataset[, 1] == digit, ]
    clusterData <- kmeans(digit_data, centers=k_initial_clusters)
    cipher_cluster[[digit + 1]] <- clusterData$centers
    label_cluster[[digit + 1]] <- c(1:k_initial_clusters)*0 + digit
  }
  # train_lab <- factor(unlist(label_cluster))
  train_dat <- do.call(rbind, cipher_cluster)
  return(train_dat)
}


k_initial_clusters = 100
train_kmeans_data <- get_k_means_clustered_data(training_data, k_initial_clusters)
test_kmeans_data <- get_k_means_clustered_data(testing_data, k_initial_clusters)
whole_kmeans_data <- get_k_means_clustered_data(id, k_initial_clusters)

```


## 3.1.2 Compare your KNN performance based on the raw training data and based on the cluster centroids of the training data. 
During the comparison you should also consider the run times of the algorithm. As the generation of clusters is based on random starting points cross-validation should be performed.

do the training of the k-NN using the centroids (new data)
``` {r test of the knn using the kmeans data using cross-validation}

# for every fold check all the K's
ks <- c(3,5,10)

plot_data_ks_l <- list()
# do the folds
folds <- createFolds(whole_kmeans_data[, 1], k = 2)
fold_no <- 0 # just for printing the progress
#current fold - to ignore in training data but to use as a validation dataset: fold -> test!
for (fold in folds){
  fold_no <- fold_no + 1
  print(paste0("fold_no =", fold_no))
  
  fold <- sample(fold) # shuffle id numbers of fold 
  
  # use not-fold data as training and fold data as test
  not_f_df <- whole_kmeans_data[ -fold, ] #training data
  f_df <- whole_kmeans_data[ fold, ] #test data
  
  #not_f_df <- shuffled_df[ -fold, ] #training data
  #f_df <- shuffled_df[ fold, ] #test data
  
  # get labels - supervision part
  f_train_labels <- not_f_df[,1]
  f_test_labels <- f_df[,1]

  # predict with KNN - test all k's for each fold
  k_no <- 0 # just to keep track

  for (k in ks){
      k_no <- k_no + 1
      
      # f_test_pred <- knn(train = not_f_df[,c(2:ncol(not_f_df))], test = f_df[,c(2:ncol(f_df))], cl = not_f_df[,1], k=k)

      print(paste0("      k =", k))
      plot_data <- knn_get_kmeans_plot_cv_data(test_data=f_df[,c(2:ncol(f_df))], test_labels=f_df[,1],
                                         train_data=not_f_df[,c(2:ncol(not_f_df))], train_labels=not_f_df[,1],
                                         fold_no=fold_no, k=k, title_info = k_initial_clusters)
      #print(plot_data)
      plot_data_ks_l <- append(plot_data_ks_l, list(plot_data))
  }
}
```
```{r }
plot_list <- plot_results_cv_kmeans(plot_data_ks_l)
# plot_list[2]
save_path <- "figures/3_1/cross_valid_kmeans/"
i<-0
for (plot in plot_list){
  i<-i+1
  ggsave(paste(save_path, "cv_kmeans_", i, ".png"), plot = plot,
       width = 15, height = 10, units = "cm")
}
```



Dear all, sorry that we did not make Task 3.1.3 of Exercise 3 very clear. In Task 3.1.3, we are asking to do K-means to reduce the size of the dataset. Subsequently, you can perform KNN for the classification task. The performance for comparison is related to the KNN.
Write comment
Karol Szurkowski
