---
title: "Exercise_3_clustering"
output: pdf_document
---

```{r setup, include=FALSE}
library(class)
library(rpart)
library(rpart.plot)
library(stats)
library(randomForest)
library(caret)
library(kernlab)
library(RSNNS)
library(neuralnet)
```

```{r}
################################
# This version: 
# - plots and computes computational code 
# - changed to 3 hidden layers with 120 nodes like Zhuoqi and (150,100,50) for PCA part

# TODO: add pre-processing from Karol's 
# TODO: Cross-validation 
# TODO: mean and variance
# TODO: a function for computing + plotting run-time maybe instead of copying same code everywhere

# current issue: takes too long to run
################################

#Load the dataset
load("data/idList-FinalExam.Rdata")

id <- do.call(rbind, idList[1:4])
id <- as.data.frame(id)
id[,1] <- factor(id[,1])

items_per_person = nrow(id) / length(idList)
id_train <- id[1:(items_per_person*9),]
id_test <- id[(items_per_person*9 + 1):(items_per_person*13),]
```

```{r}

####################################
####### 5.2: Neural Networks ####### 
####################################

#######################################################################################################
## 5.2.1
## Create a matrix (as below in grey background) for the training classes. It has N rows (the same as 
## the number of training data) and 10 columns (binary). The column with '1' marks the 
## corresponding class as the example shown below (eg. cyper '0' is represented by '1000000000').
#######################################################################################################

lev <- levels(id_train$V1) # Number of classes

# Create a list probabilities, for all labels
nnTrainingClass <- matrix(nrow = length(id_train$V1), ncol = 10, data = 0) 

for(i in 1:length(id_train$V1)) { # Set probabilities to one for matching class
  matchList <- match(lev,toString(id_train$V1[i]))
  matchList[is.na(matchList)] <- 0
  nnTrainingClass[i,] <- matchList
}
trainingClass <- as.data.frame(nnTrainingClass)

```

```{r}

############################################################################################
## 5.2.2
## Train a neural network with N inputs and 10 outputs, based on the modified training data.
############################################################################################


train_mlp <- function(training_data, training_classes, hidden_layers) {
  
  # network <- mlp(id_train[,2:ncol(id_train)], training_classes, size = hidden_layers, maxit = 200, hiddenActFunc = "Act_TanH", 
  #                learnFunc="Std_Backpropagation", learnFuncParams = c(0.01, 0))
  

  network <- mlp(id[,-1], trainingClass, size = hidden_layers, maxit = 20, hiddenActFunc = "Act_TanH",
learnFunc="Std_Backpropagation", learnFuncParams = c(0.01, 0))
  
  plot(network)

  plotIterativeError(network)

  network$IterativeFitError[200]
  
  return(network)
}

network <- train_mlp(id_train, trainingClass, c(2, 2))


```
