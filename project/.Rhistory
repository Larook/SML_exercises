# n_pcs <- ncol(id_pca) - 1  # minus label
# # splitting data disjunct
# data_train_test_disjunct <- get_training_test_data_disjunct(data=id_norm)
# train_data_disjunct <- data_train_test_disjunct[[1]]
# test_data_disjunct <- data_train_test_disjunct[[2]]
# splitting data all persons in
data_train_test_allin <- get_training_test_data_allin(data=id_norm, training_percent=70)
train_data_allin <- data_train_test_allin[[1]]
test_data_allin <- data_train_test_allin[[2]]
source("important_functions/load_data_id.R")
source("important_functions/get_training_test_data.R")
source("important_functions/get_normalized_data.R")
source("important_functions/get_gaussian_smoothed_data.R")
source("important_functions/view_data.R")
source("important_functions/get_k_clustered_cipher_data.R")
source("important_functions/get_PCA_reduced_data.R")
#loading data
id <- load_data_id(load_full=FALSE)
# get_cipher_image(data=id, row_id=1640)
# normalizing
id_norm <- get_normalized_data(id)
# get_cipher_image(data=id_norm, row_id=1640)
# gaussian smoothing
# id_smooth <- get_gaussian_smoothed_data(dataset=id, smooth_sigma=0.05)
# get_cipher_image(data=id_smooth, row_id=1640)
# PCA
# pca_obj <- get_pca_obj(id_norm)
# id_pca <- get_PCA_reduced_data(labels=id_norm$V1, pca_obj=pca_obj, searched_accum_var=85)
# n_pcs <- ncol(id_pca) - 1  # minus label
# # splitting data disjunct
# data_train_test_disjunct <- get_training_test_data_disjunct(data=id_norm)
# train_data_disjunct <- data_train_test_disjunct[[1]]
# test_data_disjunct <- data_train_test_disjunct[[2]]
# splitting data all persons in
data_train_test_allin <- get_training_test_data_allin(data=id_norm, training_percent=70)
train_data_allin <- data_train_test_allin[[1]]
test_data_allin <- data_train_test_allin[[2]]
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 5,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
paste("confusionMatrix(datasetTest,test$V1) = ", test_confusion$overall[1])
}
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 5,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("confusionMatrix(datasetTest,test$V1) = ", test_confusion$overall[1]))
}
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("confusionMatrix(datasetTest,test$V1) = ", test_confusion$overall[1]))
}
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", test_confusion$overall[1]))
datasetTrain <- predict(classifier_rbf,id_train)
train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
print(paste("train_confusion = ", train_confusion$overall[1]))
}
train_confusion
train_confusion$table
test_confusion$table
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf,id_train)
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf,id_train)
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf,id_train)
source("important_functions/load_data_id.R")
source("important_functions/get_training_test_data.R")
source("important_functions/get_normalized_data.R")
source("important_functions/get_gaussian_smoothed_data.R")
source("important_functions/view_data.R")
source("important_functions/get_k_clustered_cipher_data.R")
source("important_functions/get_PCA_reduced_data.R")
#loading data
id <- load_data_id(load_full=FALSE)
# get_cipher_image(data=id, row_id=1640)
# normalizing
id_norm <- get_normalized_data(id)
# get_cipher_image(data=id_norm, row_id=1640)
# gaussian smoothing
# id_smooth <- get_gaussian_smoothed_data(dataset=id, smooth_sigma=0.05)
# get_cipher_image(data=id_smooth, row_id=1640)
# PCA
# pca_obj <- get_pca_obj(id_norm)
# id_pca <- get_PCA_reduced_data(labels=id_norm$V1, pca_obj=pca_obj, searched_accum_var=85)
# n_pcs <- ncol(id_pca) - 1  # minus label
# # splitting data disjunct
# data_train_test_disjunct <- get_training_test_data_disjunct(data=id_norm)
# train_data_disjunct <- data_train_test_disjunct[[1]]
# test_data_disjunct <- data_train_test_disjunct[[2]]
# splitting data all persons in
data_train_test_allin <- get_training_test_data_allin(data=id_norm, training_percent=70)
train_data_allin <- data_train_test_allin[[1]]
test_data_allin <- data_train_test_allin[[2]]
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf,id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf,id_train)
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf, id_train)
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <-1
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
datasetTrain <- predict(classifier_rbf, id_train)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table))
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table)))
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <-1
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
print(paste("test_confusion = ", sum(diag(test_confusion$table))/sum(test_confusion$table)))
datasetTrain <- predict(classifier_rbf, id_train)
train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
print(paste("train_confusion = ", sum(diag(train_confusion$table))/sum(train_confusion$table)))
# }
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
for (i in 1:2){
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
print(paste("test_confusion = ", svm_test_acc))
svm_accuracy_test_list[i] <- svm_test_acc
datasetTrain <- predict(classifier_rbf, id_train)
train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
print(paste("train_confusion = ", svm_train_acc))
svm_accuracy_training_list[i] <- svm_train_acc
start_time <- Sys.time()
training_class <- get_training_class(training_data = train.cv)
nn <- train_mlp(training_data=train.cv, training_classes=training_class, size=c(80,40,20))
mlp_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
# evaluate MLP and save the time and accuracy
start_time <- Sys.time()
mlp_accuracy_test_list[i] <- evaluate_nn(nn, id_test)
time_eval_list[i] <- difftime(Sys.time(), start_time, units = "secs")
mlp_accuracy_training_list[i] <- evaluate_nn(nn, id_train)
}
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
for (i in 1:2){
# Evaluate best SVM model
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
print(paste("test_confusion = ", svm_test_acc))
svm_accuracy_test_list[i] <- svm_test_acc
datasetTrain <- predict(classifier_rbf, id_train)
train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
print(paste("train_confusion = ", svm_train_acc))
svm_accuracy_training_list[i] <- svm_train_acc
# Evaluate best MLP model
start_time <- Sys.time()
training_class <- get_training_class(training_data = train.cv)
nn <- train_mlp(training_data=train.cv, training_classes=training_class, size=c(80,40,20))
mlp_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
# evaluate MLP and save the time and accuracy
start_time <- Sys.time()
mlp_accuracy_test_list[i] <- evaluate_nn(nn, id_test)
time_eval_list[i] <- difftime(Sys.time(), start_time, units = "secs")
mlp_accuracy_training_list[i] <- evaluate_nn(nn, id_train)
}
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
for (i in 1:2){
# Evaluate best SVM model
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
datasetTest <- predict(classifier_rbf, id_test)
test_confusion <- confusionMatrix(datasetTest, id_test$V1)
svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
print(paste("test_confusion = ", svm_test_acc))
svm_accuracy_test_list[i] <- svm_test_acc
datasetTrain <- predict(classifier_rbf, id_train)
train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
print(paste("train_confusion = ", svm_train_acc))
svm_accuracy_training_list[i] <- svm_train_acc
# Evaluate best MLP model
start_time <- Sys.time()
training_class <- get_training_class(training_data = id_train)
nn <- train_mlp(training_data=id_train, training_classes=training_class, size=c(80,40,20))
mlp_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
# evaluate MLP and save the time and accuracy
start_time <- Sys.time()
mlp_accuracy_test_list[i] <- evaluate_nn(nn, id_test)
time_eval_list[i] <- difftime(Sys.time(), start_time, units = "secs")
mlp_accuracy_training_list[i] <- evaluate_nn(nn, id_train)
}
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <- 1
# Evaluate best SVM model
start_time <- Sys.time()
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <- 1
# # Evaluate best SVM model
# start_time <- Sys.time()
# classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
# svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
#
# datasetTest <- predict(classifier_rbf, id_test)
# test_confusion <- confusionMatrix(datasetTest, id_test$V1)
# svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
# print(paste("test_confusion = ", svm_test_acc))
# svm_accuracy_test_list[i] <- svm_test_acc
#
# datasetTrain <- predict(classifier_rbf, id_train)
# train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
# svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
# print(paste("train_confusion = ", svm_train_acc))
# svm_accuracy_training_list[i] <- svm_train_acc
# Evaluate best MLP model
start_time <- Sys.time()
training_class <- get_training_class(training_data = id_train)
nn <- train_mlp(training_data=id_train, training_classes=training_class, size=c(80,40,20))
library(gmodels)
library(class)
library(caret)
library(swirl)
library(ggplot2)
library(spatstat)
library(rpart)
library(rpart.plot)
library(stats)
library(randomForest)
library(caret)
library(kernlab)
library(RSNNS)
library(neuralnet)
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <- 1
# # Evaluate best SVM model
# start_time <- Sys.time()
# classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
# svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
#
# datasetTest <- predict(classifier_rbf, id_test)
# test_confusion <- confusionMatrix(datasetTest, id_test$V1)
# svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
# print(paste("test_confusion = ", svm_test_acc))
# svm_accuracy_test_list[i] <- svm_test_acc
#
# datasetTrain <- predict(classifier_rbf, id_train)
# train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
# svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
# print(paste("train_confusion = ", svm_train_acc))
# svm_accuracy_training_list[i] <- svm_train_acc
# Evaluate best MLP model
start_time <- Sys.time()
training_class <- get_training_class(training_data = id_train)
nn <- train_mlp(training_data=id_train, training_classes=training_class, size=c(80,40,20))
mlp_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
# evaluate MLP and save the time and accuracy
start_time <- Sys.time()
mlp_accuracy_test_list[i] <- evaluate_nn(nn, id_test)
time_eval_list[i] <- difftime(Sys.time(), start_time, units = "secs")
library(gmodels)
library(class)
library(caret)
library(swirl)
library(ggplot2)
library(spatstat)
library(rpart)
library(rpart.plot)
library(stats)
library(randomForest)
library(caret)
library(kernlab)
library(RSNNS)
library(neuralnet)
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
# for (i in 1:2){
i <- 1
# # Evaluate best SVM model
# start_time <- Sys.time()
# classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
# svm_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
#
# datasetTest <- predict(classifier_rbf, id_test)
# test_confusion <- confusionMatrix(datasetTest, id_test$V1)
# svm_test_acc <-sum(diag(test_confusion$table))/sum(test_confusion$table)
# print(paste("test_confusion = ", svm_test_acc))
# svm_accuracy_test_list[i] <- svm_test_acc
#
# datasetTrain <- predict(classifier_rbf, id_train)
# train_confusion <- confusionMatrix(datasetTrain, id_train$V1)
# svm_train_acc <-sum(diag(train_confusion$table))/sum(train_confusion$table)
# print(paste("train_confusion = ", svm_train_acc))
# svm_accuracy_training_list[i] <- svm_train_acc
# Evaluate best MLP model
start_time <- Sys.time()
training_class <- get_training_class(training_data = id_train)
nn <- train_mlp(training_data=id_train, training_classes=training_class, size=c(80,40,20))
mlp_time_training_list[i] <- difftime(Sys.time(), start_time, units = "secs")
# evaluate MLP and save the time and accuracy
start_time <- Sys.time()
mlp_accuracy_test_list[i] <- evaluate_nn(nn, id_test)
time_eval_list[i] <- difftime(Sys.time(), start_time, units = "secs")
library(gmodels)
library(class)
library(caret)
library(swirl)
library(ggplot2)
library(spatstat)
library(rpart)
library(rpart.plot)
library(stats)
library(randomForest)
library(caret)
library(kernlab)
library(RSNNS)
library(neuralnet)
source("NN_functions/mlp_functions.R")
mlp_accuracy_test_list <- c()
mlp_accuracy_training_list <- c()
mlp_time_training_list <- c()
svm_accuracy_test_list <- c()
svm_accuracy_training_list <- c()
svm_time_training_list <- c()
id_train <- train_data_allin
id_test <- test_data_allin
classifier_rbf <-ksvm(V1~ ., data = id_train, kernel = "polydot", C = 0.2,  degree=2, scale=0.5)
nn <- train_mlp(training_data=id_train, training_classes=get_training_class(training_data = id_train), size=c(80,40,20))
