---
title: "ex2.2_clean"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(class)
library(caret)
library(swirl)
```

# Exercise 2.2: Normalization
Perform one of the two normalizations suggested in the lecture (min-max normalization and z-
standardization) for the best parameter setting found under 2.1.3 and apply kNN with 10 fold
cross-validation (10 runs, 90% training and 10% test set).

Apply the normalization before and after PCA independently and compare the results.
Analyze the results

```{r Functions to plot the results}

# get accuracy of the labels in percents
get_accuracy <- function(predicted_labels, test_labels){
  # accuracy(table(numbers_test_pred,id_test_labels))
  tab <- table(predicted_labels, test_labels)
  sum(diag(tab)/(sum(rowSums(tab)))) * 100
}


# join labels with data - labels go as the last column
join_labels_data_dataframe <- function(labels, data){
  data$label <- labels 
  # get the labels as the first column
  data <- data[,c(ncol(data),1:(ncol(data)-1))]
  return(data)
}

# normalize data
normalize <- function(x) {
 return((x-min(x))/ (max(x)- min(x)))
}

# take the mixed dataframe with all the folds and ks and do nice plot
plot_results_cross_val <- function(cv_results_df){
  
  plot_data_df <- data.frame()
  # calculate means and sdevs
  for (k in ks){
    k_rows <- cv_results_df[cv_results_df$k_now == k, ]
    t_mean <- mean(k_rows$delta_t)
    t_sd <- sd(k_rows$delta_t)
    
    test_acc_mean <- mean(k_rows$k_accuracy_test)
    test_acc_sd <- sd(k_rows$k_accuracy_test)
    
    train_acc_mean <- mean(k_rows$k_accuracy_train)
    train_acc_sd <- sd(k_rows$k_accuracy_train)
    
    plot_data_row<- list("k_now"=k, "t_mean"=t_mean, "t_sd"=t_sd, "test_acc_mean"=test_acc_mean, "test_acc_sd"=test_acc_sd, "train_acc_mean"=train_acc_mean, "train_acc_sd"=train_acc_sd)
    plot_data_df <- rbind(plot_data_df, as.data.frame(plot_data_row))
  }
  
  main <- paste("cross validation 10 folds")
  
  g_time <- ggplot(plot_data_df, aes(x=k_now)) + 
    geom_line(aes(y=t_mean)) + 
    geom_ribbon(aes(ymax=t_mean+t_sd, ymin=t_mean-t_sd), fill="pink", alpha=.5) +
    labs(title=main, 
         subtitle="execution time knn", 
         caption="Source: abcd", 
         y="time [ms]",
         x="k-number of nearest neighbours") 
  
  colors <- c("test data" = "darkgreen", "train data" = "darkblue" )
    g_accuracy <- ggplot(plot_data_df, aes(x=k_now)) + 
    geom_line(aes(y=test_acc_mean, color="test data")) + 
    geom_ribbon(aes(ymax=test_acc_mean+test_acc_sd,
                    ymin=test_acc_mean-test_acc_sd), fill="green", alpha=.5) +
    geom_line(aes(y=train_acc_mean, color="train data")) + 
    geom_ribbon(aes(ymax=train_acc_mean+train_acc_sd, ymin=train_acc_mean-train_acc_sd), fill="blue", alpha=.5) +
  labs(title=main, 
         subtitle="accuracy comparison", 
         caption="Source: abcd", 
         y="accuracy [%]",
         x="k-number of nearest neighbours",
        color = "Legend") +
    scale_color_manual(values = colors)
  
  list_of_plots <- list(g_time, g_accuracy)
  
  return(list_of_plots)
}

```


## 2.2 Normalization
## Min-Max Normalization Before PCA 
``` {r prepare reduced dims dataset}
# All persons in
# load("../data/idList-co-100.Rdata")  
load("../data/idList-cornered-100-2021.Rdata") 
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING


# DO NORMALIZATION
shuffled_df <- as.data.frame(lapply(id[,c(2:325)], normalize))
origin_labels <- id$V1
origin_data <- id[,c(2:325)]
normalized_data <- as.data.frame(lapply(origin_data, normalize))

# join labels with data
shuffled_df <- join_labels_data_dataframe(labels=origin_labels , data=normalized_data)

##Shuffling the data-------------------------------------------------------------------
set.seed(423)
shuffled_df <- shuffled_df[sample(nrow(shuffled_df)),]
accumulated_variance_v <- c(80) ## Karol said 80% fastest

#Split 50/50
test_rows_id <- 1:(nrow(shuffled_df)/2)
train_rows_id <- ((nrow(shuffled_df)/2) + 1) :nrow(shuffled_df)

##PCA------------------------------------------------------------------------------------
df_pca <- prcomp(x=shuffled_df[,(2:ncol(shuffled_df))], scale = TRUE, center = TRUE, rank.=21)
# take only .x and add labels

id_labels <- shuffled_df[, 1]
df_reduced <- join_labels_data_dataframe(labels=id_labels , data=as.data.frame(df_pca$x))

```

```{r based on exc1 cross validation}

cv_results_df <- data.frame()
# for every fold check all the ks
ks <- c(5, 15, 25, 35, 45)

# do the folds
folds <- createFolds(df_reduced$label, k = 10)

fold_no <- 0 # just for printing the progress
#current fold - to ignore in training data but to use as a validation dataset: fold -> test!
for (fold in folds){
  fold_no <- fold_no + 1
  #print(paste0("fold_no =", fold_no))
  
  fold <- sample(fold) # shuffle id numbers of fold 
  
  # use not-fold data as training and fold data as test
  not_f_df <- df_reduced[ -fold, ]
  f_df <- df_reduced[ fold, ]
  
  # get labels 
  f_train_labels <- not_f_df[,1]
  f_test_labels <- f_df[,1]
  
  # predict with knn - test all k's for each fold

  k_no <- 0 # just to keep track
  for (k in ks){
    k_no <- k_no + 1
    ######################
    # get the prediction
    t_start <- as.numeric(proc.time())
    numbers_test_pred <- knn(train = not_f_df[,c(2:ncol(not_f_df))], test = f_df[,c(2:ncol(f_df))], cl = f_train_labels, k=k)
    t_end <- as.numeric(proc.time())
    delta_t <- (t_end -  t_start)[3]  # seconds

    # see the performance on testing data
    k_accuracy_test <-get_accuracy(f_test_labels, numbers_test_pred)
    
    # check the performance on testing data
    numbers_train_pred <- knn(train = not_f_df[,c(2:ncol(not_f_df))], test = not_f_df[,c(2:ncol(f_df))], cl = f_train_labels, k=k)
    k_accuracy_train <-get_accuracy(f_train_labels, numbers_train_pred)
      
    # do list - save everything
    data_from_knn<- list("fold_no"=fold_no, "k_now"=k, "delta_t"=delta_t, "k_accuracy_test"=k_accuracy_test, "k_accuracy_train"=k_accuracy_train )
    
    # save the results as a row to the dataframe
    cv_results_df <- rbind(cv_results_df, as.data.frame(data_from_knn) )
  }
}

#print(paste0("mse_k_all_folds_avg = ", mse_k_all_folds_avg))
# plot(ks, mse_k_all_folds_avg, type="o", ylab="missclassification error", main="each k had checked the folds")
```

```{r extract means and stdevs for each measurement for each k and plot}

plots <- plot_results_cross_val(cv_results_df)
print(plots[1])
print(plots[2])
```


## Min-Max Normalization After PCA
``` {r prepare reduced dims dataset}
# All persons in
# load("../data/idList-co-100.Rdata")  
load("../data/idList-cornered-100-2021.Rdata") 
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING

##Shuffling the data-------------------------------------------------------------------
set.seed(423)
shuffled_df <- id[sample(nrow(id)),]
#shuffled_df <- shuffled_df[sample(nrow(shuffled_df)),]

#Split 50/50
test_rows_id <- 1:(nrow(shuffled_df)/2)
train_rows_id <- ((nrow(shuffled_df)/2) + 1) :nrow(shuffled_df)

##PCA------------------------------------------------------------------------------------
df_pca <- prcomp(x=shuffled_df[,(2:ncol(shuffled_df))], scale = TRUE, center = TRUE, rank.=21)
# take only .x and add labels

id_labels <- shuffled_df[, 1]
df_reduced <- join_labels_data_dataframe(labels=id_labels , data=as.data.frame(df_pca$x))

df_reduced_norm <- as.data.frame(lapply(df_reduced[,(2:ncol(df_reduced))], normalize))
df_reduced <- join_labels_data_dataframe(labels=id_labels , data=as.data.frame(df_reduced_norm))

```

```{r based on exc1 cross validation}

cv_results_df <- data.frame()
# for every fold check all the ks
ks <- c(5, 15, 25, 35, 45)

# do the folds
folds <- createFolds(df_reduced$label, k = 10)

fold_no <- 0 # just for printing the progress
#current fold - to ignore in training data but to use as a validation dataset: fold -> test!
for (fold in folds){
  fold_no <- fold_no + 1
  #print(paste0("fold_no =", fold_no))
  
  fold <- sample(fold) # shuffle id numbers of fold 
  
  # use not-fold data as training and fold data as test
  not_f_df <- df_reduced[ -fold, ]
  f_df <- df_reduced[ fold, ]
  
  # get labels 
  f_train_labels <- not_f_df[,1]
  f_test_labels <- f_df[,1]
  
  # predict with knn - test all k's for each fold

  k_no <- 0 # just to keep track
  for (k in ks){
    k_no <- k_no + 1
    ######################
    # get the prediction
    t_start <- as.numeric(proc.time())
    numbers_test_pred <- knn(train = not_f_df[,c(2:ncol(not_f_df))], test = f_df[,c(2:ncol(f_df))], cl = f_train_labels, k=k)
    t_end <- as.numeric(proc.time())
    delta_t <- (t_end -  t_start)[3]  # seconds

    # see the performance on testing data
    k_accuracy_test <-get_accuracy(f_test_labels, numbers_test_pred)
    
    # check the performance on testing data
    numbers_train_pred <- knn(train = not_f_df[,c(2:ncol(not_f_df))], test = not_f_df[,c(2:ncol(f_df))], cl = f_train_labels, k=k)
    k_accuracy_train <-get_accuracy(f_train_labels, numbers_train_pred)
      
    # do list - save everything
    data_from_knn<- list("fold_no"=fold_no, "k_now"=k, "delta_t"=delta_t, "k_accuracy_test"=k_accuracy_test, "k_accuracy_train"=k_accuracy_train )
    
    # save the results as a row to the dataframe
    cv_results_df <- rbind(cv_results_df, as.data.frame(data_from_knn) )
  }
}

#print(paste0("mse_k_all_folds_avg = ", mse_k_all_folds_avg))
# plot(ks, mse_k_all_folds_avg, type="o", ylab="missclassification error", main="each k had checked the folds")
```

```{r extract means and stdevs for each measurement for each k and plot}

plots <- plot_results_cross_val(cv_results_df)
print(plots[1])
print(plots[2])
```