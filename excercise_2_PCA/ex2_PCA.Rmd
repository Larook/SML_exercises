---
title: "exercise2_group4_PCA"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gmodels)
library(class)
library(caret)
library(swirl)
```

# Excercise 2.1 Principal Component Analysis (PCA)
Perform a PCA on the data for the “all persons in” and “disjunct” data set.

PCA loading vector - the directions in feature space along which the data vary the most
PCA scores - projections along these directions

# 2.1.1 Show the standard deviation (From prcomp Eigenvalues), the proportion of variance and the cumulative sum of variance of the principal components. 

# In the report the first 10-20 principal components, should be sufficient to illustrate the tendencies.

```{r}
print_plots_pca <- function(data){
  
  data_pca <- prcomp(shuffled_df[,c(2:235)], center = TRUE, scale. = TRUE)
  pca_summary <- summary(data_pca)
  #print(pca_summary)
  
  #using this: https://www.datacamp.com/community/tutorials/pca-analysis-r
  
  pca_std_var <-pca_summary$importance[1,1:20]
  plot(pca_std_var, main ="Standard Deviation of 20 first PCAs")
  
  pca_proportion_var <-pca_summary$importance[2,1:20]
  plot(pca_proportion_var, main ="Proportion of Variance of 20 first PCAs")
  
  pca_cumulative_var <-pca_summary$importance[3,1:20]
  plot(pca_cumulative_var, main ="Cumulative Proportion of 20 first PCAs")

}
# Zhuoqi has said in class to do it using Eigenvalues but summary seems to work just as well. 
# Must do it with All persons in (everyone used as training data) + Disjunct dataset (still unclear about that one)

#From Karol's code: 
# All persons in
load ("data/idList-co-100.Rdata") 
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING

set.seed(423)
shuffled_df <- id[sample(nrow(id)),]
print_plots_pca(shuffled_df)

# Disjunct data
#id <- idList[[1]]
#shuffled_df <- id[sample(nrow(id)),]
#print_plots_pca(shuffled_df)

```

## 2.1.2 Show the performance of selecting enough principal components to represent 80%, 90%, 95%, 99% of the accumulated variance. For each test vary “k” in kNN, try 3 reasonable values.

## KNN PERSON INDEPENDENT 
```{r}
load ("data/idList-co-100.Rdata") 
dataset <- data.frame(id)
set.seed(42)
dataset_shuffle <- dataset[sample(nrow(dataset)),]

# normalization ? 
minTest = nrow(dataset)*0.90
maxTest = nrow(dataset)
  
dataset_train_labels <- dataset_shuffle[1:minTest - 1,1]
dataset_test_labels <- dataset_shuffle[minTest:maxTest,1]

# PCA reduction on data set 

dataset_knn <- function(dataset, filterOutLabels=TRUE, reappendLabels=FALSE) {
  ## Filter out the first one due to it being the label
  if(filterOutLabels){
    ds = prcomp(dataset[,2:ncol(dataset)], center = TRUE, scale. = TRUE)
  } else {
    ds = prcomp(dataset, center = TRUE, scale. = TRUE)
  }
}

#still not sure what's the point of these: normalization step? 
ds_train_xs <- dataset_knn$x[1:minTest-1,]
ds_test_xs <- dataset_knn$x[minTest:maxTest,]

#removed new stuff from other repo
#Kept getting error (issue with Rstudio or project?)


```

TODO: 
- change number of K's used 
- Use different dataset for this (New one with best parameter from 2.1 from Karol)
- Use All persons-in and Disjunct (Both? one?)

## 2.2 Normalization

``` {r}

# All persons in
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING

set.seed(423)
shuffled_df <- id[sample(nrow(id)),]

##create a random number equal 90% of total number of rows
 ran <- sample(1:nrow(id),0.5 * nrow(id))

# Normalizing numeric data
normalize <- function(x) {
  return((x-min(x))/ (max(x)- min(x)))
}

shuffle_df <- as.data.frame(lapply(id[,c(2:325)], normalize))

## Apply KNN with 10 fold CrossV

# for every fold check all the ks
ks <- c(1,17,29)
mse_k_all_folds_avg <- rep(0, length(ks)) # vector for storing error of each k 

# do the folds
folds <- createFolds(shuffled_df, k = 10)

fold_no <- 0 # just for printing the progress

#current fold - to ignore in training data but to use as a validation dataset: fold -> test!
for (fold in folds){
  fold_no <- fold_no + 1
  print(paste0("fold_no =", fold_no))
  
  fold <- sample(fold) # shuffle id numbers of fold 
  
  # use not-fold data as training and fold data as test
  not_f_df <- shuffled_df[ -fold, ]
  f_df <- shuffled_df[ fold, ]
  
  # get labels 
  f_train_labels <- not_f_df[,1]
  f_test_labels <- f_df[,1]
  
  # predict with knn - test all k's for each fold
  k_no <- 0 # just to keep track
  k_error <- 0
  for (k in ks){
    k_no <- k_no + 1
    f_test_pred <- knn(train = not_f_df[,c(2:325)], test = f_df[,c(2:325)], cl = f_train_labels, k=k)
    
    k_error <- mean(f_test_labels != f_test_pred) # error of current k in this fold
    print(paste0("      k =", k, " k_error =", k_error))
    print( mse_k_all_folds_avg) # Error vector that we want to plot
    
    # we just want to plot the results so we came up with idea of saving the errors in vector
    # for each k in the vector all the folds are summed up together, and then we get the average
    mse_k_all_folds_avg[k_no] <- mse_k_all_folds_avg[k_no] + k_error
  }
}
mse_k_all_folds_avg <- mse_k_all_folds_avg / length(folds)
#print(paste0("mse_k_all_folds_avg = ", mse_k_all_folds_avg))
#plot(ks, mse_k_all_folds_avg, type="o", ylab="missclassification error", main="each k had checked the folds")

##PCA
df_pca <- prcomp(x=shuffled_df[,(2:ncol(shuffled_df))], scale = TRUE, center = TRUE)
#df_pca <- prcomp(id[,(2:ncol(id))], center = TRUE,scale. = TRUE)
pca_sum <- summary(df_pca)
#print(pca_sum$x)


## Plots for comparison! 


```

```{r}
## Min-Max Normalization After PCA

# All persons in
load("data/idList-co-100.Rdata")
id <- do.call(rbind, idList[1:10])
id <- as.data.frame(id)
id$V1 <- factor(id$V1)
# id - huge dataframe with everyone as TRAINING

set.seed(423)
shuffled_df <- id[sample(nrow(id)),]

##create a random number equal 90% of total number of rows
 ran <- sample(1:nrow(id),0.5 * nrow(id))

# Normalizing numeric data
normalize <- function(x) {
  return((x-min(x))/ (max(x)- min(x)))
}

## Apply KNN with 10 fold CrossV

# for every fold check all the ks
ks <- c(1,17,29)
mse_k_all_folds_avg <- rep(0, length(ks)) # vector for storing error of each k 

# do the folds
folds <- createFolds(shuffled_df, k = 10)

fold_no <- 0 # just for printing the progress

#current fold - to ignore in training data but to use as a validation dataset: fold -> test!
for (fold in folds){
  fold_no <- fold_no + 1
  print(paste0("fold_no =", fold_no))
  
  fold <- sample(fold) # shuffle id numbers of fold 
  
  # use not-fold data as training and fold data as test
  not_f_df <- shuffled_df[ -fold, ]
  f_df <- shuffled_df[ fold, ]
  
  # get labels 
  f_train_labels <- not_f_df[,1]
  f_test_labels <- f_df[,1]
  
  # predict with knn - test all k's for each fold
  k_no <- 0 # just to keep track
  k_error <- 0
  for (k in ks){
    k_no <- k_no + 1
    f_test_pred <- knn(train = not_f_df[,c(2:325)], test = f_df[,c(2:325)], cl = f_train_labels, k=k)
    
    k_error <- mean(f_test_labels != f_test_pred) # error of current k in this fold
    print(paste0("      k =", k, " k_error =", k_error))
    print( mse_k_all_folds_avg) # Error vector that we want to plot
    
    # we just want to plot the results so we came up with idea of saving the errors in vector
    # for each k in the vector all the folds are summed up together, and then we get the average
    mse_k_all_folds_avg[k_no] <- mse_k_all_folds_avg[k_no] + k_error
  }
}
mse_k_all_folds_avg <- mse_k_all_folds_avg / length(folds)
#print(paste0("mse_k_all_folds_avg = ", mse_k_all_folds_avg))
#plot(ks, mse_k_all_folds_avg, type="o", ylab="missclassification error", main="each k had checked the folds")

##PCA
df_pca <- prcomp(x=shuffled_df[,(2:ncol(shuffled_df))], scale = TRUE, center = TRUE)
#df_pca <- prcomp(id[,(2:ncol(id))], center = TRUE,scale. = TRUE)
pca_sum <- summary(df_pca)
#print(pca_sum$x)

shuffle_df <- as.data.frame(lapply(id[,c(2:325)], normalize))

## Plots for comparison! 

```





